{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDkLJRB485-0",
        "outputId": "8413956b-abf5-45ba-ba23-92fde48ee3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fGaasPg89FYf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df=pd.read_csv(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPbJGML-LZR",
        "outputId": "2203fc89-9042-4388-ac42-395442aa8d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHDtvIBu-M4Z",
        "outputId": "a6bef746-f9ff-4f67-ae8e-38c36ade3fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1jRM4H8C-Q13"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "import string\n",
        "\n",
        "import contractions\n",
        "\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "from tabulate import tabulate\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P2KW6SR-YpZ",
        "outputId": "66846165-6648-4aa9-b4dd-cbfae12d4028"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPYAcjNB9F06",
        "outputId": "b0ba2d47-b9b7-4e05-8cbd-8f9d425dd23e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                   title  \\\n",
              "0                        Envy to other is swallowing me   \n",
              "1     Nothin outta the ordinary. Paradise. Job stres...   \n",
              "2     Almost 49 and the chasm of emptiness has never...   \n",
              "3                                       I’m happy again   \n",
              "4     Is it possible to recover from such a traumati...   \n",
              "...                                                 ...   \n",
              "3118                 Positive relief ideas with stress?   \n",
              "3119                                          Breakdown   \n",
              "3120  I feel as if I actually died a long time ago a...   \n",
              "3121  Is it wierd that i have imaginary friends at t...   \n",
              "3122                              Head and Eye Pressure   \n",
              "\n",
              "                                                   body  \\\n",
              "0     Im from developingcountry, Indonesia , and for...   \n",
              "1     Um hello ....well many can relate im sure. Aft...   \n",
              "2     I’ve been diagnosed severe bi polar where you ...   \n",
              "3     After my closest friend left me in April, I ha...   \n",
              "4     I am only 15, and yet I feel my life is alread...   \n",
              "...                                                 ...   \n",
              "3118  Hi all, my mom has been working from home sinc...   \n",
              "3119  I really think I lost my mind last night, I’d ...   \n",
              "3120  I feel like I died a long time ago and I just ...   \n",
              "3121  16f ... cant manage to make friends and get ov...   \n",
              "3122  Since October (for the last 4 months) I have h...   \n",
              "\n",
              "                                             Body_Title  label  \n",
              "0     Envy to other is swallowing me Im from develop...      1  \n",
              "1     Nothin outta the ordinary. Paradise. Job stres...      1  \n",
              "2     Almost 49 and the chasm of emptiness has never...      1  \n",
              "3     I’m happy again After my closest friend left m...      0  \n",
              "4     Is it possible to recover from such a traumati...      1  \n",
              "...                                                 ...    ...  \n",
              "3118  Positive relief ideas with stress? Hi all, my ...      1  \n",
              "3119  Breakdown I really think I lost my mind last n...      1  \n",
              "3120  I feel as if I actually died a long time ago a...      1  \n",
              "3121  Is it wierd that i have imaginary friends at t...      1  \n",
              "3122  Head and Eye Pressure Since October (for the l...      1  \n",
              "\n",
              "[3123 rows x 4 columns]>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MladCYIZ9K2b"
      },
      "outputs": [],
      "source": [
        "del df['title']\n",
        "del df['body']\n",
        "df.rename(columns={'Body_Title':'content'},inplace=True)\n",
        "df.rename(columns={'label':'sentiment'},inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Nf2MfrW_9aDO"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = df.copy()\n",
        "\n",
        "x = np.array(train['content'].values)\n",
        "y = np.array(train['sentiment'].values)\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "labels = np.unique(encoder.inverse_transform(y))\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "tf1 = TfidfVectorizer(analyzer='word', max_features=1000, ngram_range=(1,3))\n",
        "x_train = tf1.fit_transform(x_train).toarray()\n",
        "x_test = tf1.transform(x_test).toarray()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__bjanqQ-AVX",
        "outputId": "8530ec93-d6b2-4133-c42d-dc3c1e6b1207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Classifier Accuracy: 0.93\n",
            "Best Random Forest Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "Best XGBoost Parameters: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "\n",
        "rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid=rf_param_grid, cv=3)\n",
        "xgb_grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid=xgb_param_grid, cv=3)\n",
        "\n",
        "\n",
        "rf_grid_search.fit(x_train, y_train)\n",
        "xgb_grid_search.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "best_rf_classifier = rf_grid_search.best_estimator_\n",
        "best_xgb_classifier = xgb_grid_search.best_estimator_\n",
        "\n",
        "\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('rf', best_rf_classifier),\n",
        "    ('xgb', best_xgb_classifier)\n",
        "], voting='hard')\n",
        "\n",
        "voting_classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = voting_classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Voting Classifier Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "best_rf_params = best_rf_classifier.get_params()\n",
        "best_xgb_params = best_xgb_classifier.get_params()\n",
        "\n",
        "print(\"Best Random Forest Parameters:\", best_rf_params)\n",
        "print(\"Best XGBoost Parameters:\", best_xgb_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI_nHs_5-r0F",
        "outputId": "95175ed7-4c04-4129-c654-41685df8eb99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['voting_classifier_model.pkl']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(voting_classifier, 'voting_classifier_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idCwt3EvPXXF",
        "outputId": "6ecd8a08-0bda-4394-eb99-b383bc304ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              content  sentiment\n",
            "3   I’m happy again After my closest friend left m...          0\n",
            "18  Screen Time Negatives I feel like these screen...          0\n",
            "24  End of Semester Ah!!!! I’m almost done with th...          0\n",
            "36  The love of my life, mother of my child, fianc...          0\n",
            "38  Chat? Anyone just wanna chat in this thread? C...          0\n",
            "                                             content  sentiment\n",
            "0  Envy to other is swallowing me Im from develop...          1\n",
            "1  Nothin outta the ordinary. Paradise. Job stres...          1\n",
            "2  Almost 49 and the chasm of emptiness has never...          1\n",
            "4  Is it possible to recover from such a traumati...          1\n",
            "5  I’m finding it hard to find a reason to get up...          1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "s=df[df['sentiment']==0].iloc[0:5]\n",
        "s1=df[df['sentiment']==1].iloc[0:5]\n",
        "print(s)\n",
        "print(s1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkPrHFGYJdG1",
        "outputId": "c000a92e-498b-4e50-f2e3-efaeb84c9847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "para=\"it was a great day . i am really happy\"\n",
        "\n",
        "para=[para]\n",
        "vectorized = tf1.transform(para).toarray()\n",
        "\n",
        "predictions=voting_classifier.predict(vectorized)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ2vLz-EKJhh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
